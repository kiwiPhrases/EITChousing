{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EITC Housing Benefits\n",
    "In this notebook, we try to estimate the cost of a hypothetical EITC program to aid with rental housing payments. The aim is to supply a family with enough EITC to have them pay no more than 30% of their income for housing. Namely, the algorithm we implement is as follows:\n",
    "\n",
    "Let $y_i$ denote the income of family $i$. Furthermore, suppose that family $i$ has characteristics married $s \\in \\{0,1\\}=S$ and children $c \\in \\{0,\\dots, 3\\}=C$. For convenience, let the family type $t\\in C \\times S$. Suppose $y_i$ is such that it qualifies family $i$ for $e_i = e(y_i,s,c)$ amount of EITC benefits. Finally, suppose that family $i$ lives in location $l$ and pays rent $r$ for a $b\\in \\{0,\\dots,4\\}$ bedroom housing unit. Then, under our scheme, family $i$ will receive additional EITC housing benefits $h$ of:\n",
    "\n",
    "$$h_{l,t,y} = max(r_{l,b} - .3(y_i+e_i(y_i,s,c)), 0 )$$\n",
    "\n",
    "#### Data\n",
    "We have 3 datasets containing the following information:\n",
    "\n",
    "1. Number of EITC recipients in 356 metros per income bracket. \n",
    "2. Number of EITC recipients in 356 metros per number of children.\n",
    "3. Amount of EITC benefits one receives for various income levels and family characteristics (ie marriage and number of childre)\n",
    "4. The FMRs in 356 metros per number of bedrooms of the housing unit.\n",
    "\n",
    "#### Assumptions\n",
    "1. Two datasets, taxes and FMRs, are merged based on their CDSA codes but not all of the codes match. Namely, the tax data contains 381 metros but only 351 of them match to the FMR data. We are able to match an additional 5 CDSA codes for a total of 356 metros. However, there is no guarantee that the additional 5 metros match precisely with the metro of the Brookings data. For example, the FMR data contain a CDSA as 'Santa Barbara-Santa Maria-Goleta' while the tax has CDSA 'Santa Maria-Santa Barbara'. clearly, the FMR area is larger but in adding the 5 metros, we disregard this discrepancy. \n",
    "\n",
    "2. We have a distribution of files incomes in each metro area. The distributions are binned in increments of \\$5k up to \\$40k and then are binned at \\$10k increments. Since we only have the number of people who filed within each bin, we assume a uniform distribution of incomes in each bin and use the bin mean as the representative income for that bin. However, the highest income for which EITC benefits are given is \\$52400k but we must rely on \\$55k. The latter will overestimate the income and number of EITC recipients in that bin. One proposal to mediate that is to divide the bin \\$50-\\$60k in half and to use \\$52500 as the median and half the number of \\$50-\\$60k as the filers.\n",
    "\n",
    "3. We do not have any figures on marriage but need to differentiate between married and unmarried families. Consequently, we employ *1-50.2% -*figure from some Christian Science article*- as the proportion of adults married. In doing so, we must assume that marriage rates across the income distribution, number of children, and metros do not vary. \n",
    "\n",
    "4. Both FMR and EITC data are for year 2014 whereas the tax data is for year 2013. Thus, we assume that FMRs and EITC benefits do not differ drastically between 2013 and 2014. \n",
    "\n",
    "5. We only have numbers aggregated based on children and based on income bins but not across both; therefore, to estimate the proportion of families with each child type in each income bin, we assume that the number of children a family has does not vary across the income distributions. \n",
    "\n",
    "6. Consider the following variables: \n",
    "\n",
    "  * the number $n_{c,l}$ of EITC eligible families in metro $l$ and with number of children $c\\in \\{0,1,2,3+\\}$\n",
    "  * the number $m_{b,l}$ of EITC filers in each metro $l$ and income bin $b \\in \\{1,2,\\dots, 10\\}$\n",
    "\n",
    "  The tax data contains two sets of numbers data: 1) the number $n_l = \\sum_{c} n_{c,l}$ of EITC eligible people in each metro for each family type 2) the number $m_l = \\sum_{b} m_{b,l}$ of families who filed for EITC in each income bracket. Note $n_l \\geq m_l \\quad \\forall l$. To acquire the number of family types in each income bracket, we calculate\n",
    "\n",
    "  $$p_{l,c} = \\frac{n_{l,c}}{n_{l}}$$\n",
    "\n",
    "  then compute \n",
    "\n",
    "  $$k_{c,l,b} = p_{l,c} \\times m_{b,l}$$\n",
    "\n",
    "  Where $k_{c,l,b}$ is the number of families with children $c$ and in income bin $b$ in metro $l$. Of course, for this we must assume that the proportions among the eligible hold equally among those who actually file. Finally, let $T(p_{l,c})$ be the total cost calculated using eligible counts and let $T(p_{l,b})$ be that total cost calculated using bin proportions then \n",
    "$$T(p_{l,c}) \\geq T(p_{l,b})$$\n",
    "\n",
    "7. Unlike in the tax data, in which all cbsa codes are unique, the FMR data sometimes contains multiple entries for the same cbsa, albeit over different jurisdictions. Most of the repeats of cbsa codes in the FMR data are also duplicates but, on occasion, there are deviations within a particular cbsa code such as NY - 35620. To give some weight to differentials within cbsa FMR entries, we take the mean within duplicated cbsa codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Load modules and set data path:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import re\n",
    "data_path = \"C:/Users/SpiffyApple/Documents/USC/RaphaelBostic/EITChousing\"\n",
    "output_container = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "################### load tax data ###############################\n",
    "#upload tax data\n",
    "tx_o = pd.read_csv(\"/\".join([data_path, \"metro_TY13.csv\"]))\n",
    "\n",
    "#there is some weird formatting in the data due to excel -> fix:\n",
    "tx_o['cbsa'] = tx_o.cbsa.apply(lambda x: re.sub(\"=|\\\"\", \"\",x))\n",
    "\n",
    "#numerous numerical column entries have commas -> fix:\n",
    "tx_o.iloc[:,3:] = tx_o.iloc[:,3:].replace(\",\", \"\",regex=True).astype(np.int64)\n",
    "\n",
    "#set the cbsa as the dataframe index:\n",
    "tx_o.set_index('cbsa', inplace=True)\n",
    "\n",
    "#for convenience, extract cols corresponding with number of ppl filed for EITC in each income bracket\n",
    "eagi_cols = tx_o.columns[tx_o.columns.str.contains(\"EAGI\")]\n",
    "\n",
    "#cut the 50-60 bin number in half according to assumptions\n",
    "tx_o['EAGI50_13'] = tx_o['EAGI50_13']/2\n",
    "#tx_o['EAGI40_13'] = tx_o['EAGI40_13']/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveat:\n",
    "The cell below is the longest running part of this code because we must interact with excel, individually load 9 sheets, and then concatenate them into a single dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "###################### Read EITC data ###########################\n",
    "##parse the EITC data:\n",
    "eitc = pd.ExcelFile(\"/\".join([data_path, \"EITC Calculator-2-14.xlsx\"]))\n",
    "sheets = eitc.sheet_names\n",
    "eitc.close()\n",
    "\n",
    "eitc_dict = pd.read_excel(\"/\".join([data_path, \"EITC Calculator-2-14.xlsx\"]), sheetname =  sheets[9:17], skiprows = 14 )\n",
    "\n",
    "eitc_o = pd.concat(eitc_dict)\n",
    "\n",
    "#################################################################\n",
    "################### Process eitc_o data ###########################\n",
    "eitc_o = eitc_o.iloc[:,[0,40]]\n",
    "eitc_o.dropna(inplace=True)\n",
    "eitc_o = eitc_o.loc[eitc_o[2014]>0,:]\n",
    "eitc_o.reset_index(level=0, inplace=True)\n",
    "eitc_o.reset_index(drop=True, inplace=True)\n",
    "#eitc_o['num_kids'] = eitc_o.level_0.str.extract(\"(\\d)\", expand=False)\n",
    "#eitc_o['married'] = eitc_o.level_0.str.contains(\"Married\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eitc_o.to_csv(\"./EITC_benefits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of CBSAs between tax and fmr data matches?: True\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "################# Read & process fmr data  ######################\n",
    "#read in fmr data\n",
    "fmr_o1 = pd.read_excel(\"/\".join([data_path, \"FY2014_4050_RevFinal.xls\"]))\n",
    "\n",
    "#drop non Metro areas:\n",
    "fmr_o1 = fmr_o1[fmr_o1.Metro_code.str.contains(\"METRO\")]\n",
    "\n",
    "#extract cbsa code:\n",
    "fmr_o1['cbsa'] = fmr_o1.Metro_code.str.extract(\"RO(\\d{4,5})[MN]\", expand=False)\n",
    "\n",
    "#edit FMR CBSA codes to match tax CBSA codes:\n",
    "cbsa_chng_map = {'14060':'14010', '29140':'29200', '31100':'31080', '42060':'42200', '44600':'48260'}#, '36061':'35620'}\n",
    "fmr_o1.cbsa.replace(cbsa_chng_map, inplace=True)\n",
    "\n",
    "#fetch columns that pertain to FMR figures\n",
    "fmr_cols = fmr_o1.columns[fmr_o1.columns.str.contains(\"fmr\\d\")]\n",
    "\n",
    "#clean up the area names by removing \"MSA and HUD Metro FMR Area\"\n",
    "fmr_o1['Areaname'] = fmr_o1.Areaname.apply(lambda x: re.sub(\" MSA| HUD Metro FMR Area\", \"\", x))\n",
    "\n",
    "#drop duplicates based on cbsa code:\n",
    "#fmr_o = fmr_o.drop_duplicates('cbsa')\n",
    "fmr_o2 = fmr_o1.groupby(\"cbsa\").mean()[fmr_cols]\n",
    "fmr_o = pd.concat([fmr_o2, fmr_o1[['cbsa', 'Areaname']].drop_duplicates(\"cbsa\").set_index(\"cbsa\")],axis=1)\n",
    "\n",
    "\n",
    "#set an interpratable index\n",
    "#fmr_o.set_index(\"cbsa\", inplace=True)\n",
    "\n",
    "#subset to only matching cbsa codes between tax and fmr data\n",
    "common_cbsa = fmr_o.index.intersection(tx_o.index)\n",
    "\n",
    "fmr_o = fmr_o.loc[common_cbsa]\n",
    "tx_o = tx_o.loc[common_cbsa]\n",
    "\n",
    "fmr_o[fmr_cols] = (fmr_o[fmr_cols])*12\n",
    "\n",
    "print(\"The number of CBSAs between tax and fmr data matches?:\", fmr_o.shape[0] == tx_o.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "##0. Define function to calculate eitc\n",
    "######################################\n",
    "def calc_haus_eitc(group, income, fmr):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        1. group - (pd.df) subset of data frame by family type\n",
    "        2. income - (int64) total income the family earns\n",
    "    OUTPUT:\n",
    "        1. aid - (pd.Series) a series containing eitc housing aid for each family type for a given income\n",
    "    DESCRIPTION:\n",
    "        The function is basically the max(r - (y+e)*.3, 0) but if we are at income levels that don't qualify\n",
    "        a family type for EITC benefits then we need to output a corresponding vector of NAN values so that\n",
    "        the groupby operation doesn't error out on its concatenation step.\n",
    "    \"\"\"\n",
    "    details = group[group['Nominal Earnings'] == income]\n",
    "    if details.shape[0] > 0:\n",
    "        aid = fmr[details.r_type]-details.haus_share.iloc[0]\n",
    "        aid[aid<0] = 0\n",
    "    else:\n",
    "        aid = pd.DataFrame(np.array([np.nan]*fmr.shape[0]))\n",
    "        aid.index = fmr.index\n",
    "        #aid.columns = [group.r_type.iloc[0]]\n",
    "    aid.columns = ['aid']\n",
    "    return(aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Housing Share\n",
    "EITC data contain the amount of EITC benefits a family receives for a given income level. The goal here is to get a family's total income and what would be considered a fair share of income for housing. This is where we perform following aforementioned calculation:\n",
    "\n",
    "$$\\text{total income} = y_i + e_i(s,c)$$\n",
    "$$\\text{housing share} = .3\\times \\text{ total income} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate fair share of income for housing\n",
    "eitc = eitc_o[['Nominal Earnings','level_0', 2014]].copy()\n",
    "eitc['total_income'] = eitc['Nominal Earnings']+eitc[2014]\n",
    "percent_of_income=.3\n",
    "eitc['haus_share'] = eitc.total_income*percent_of_income\n",
    "\n",
    "#remove \"Nominal\" from family description.\n",
    "eitc.level_0.replace(\", Nominal\", \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "##I. Make a vector of income bin means\n",
    "######################################\n",
    "min_earn = 2500\n",
    "mid_earn = 37500\n",
    "step = 5000\n",
    "income_vect = np.linspace(min_earn,mid_earn,((mid_earn-min_earn)/step+1))\n",
    "\n",
    "add_vect = [45000,52400]\n",
    "income_vect = np.concatenate([income_vect, add_vect])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping children to bedrooms\n",
    "In order to estimate relate FMR data to family types, we must map the number of bedrooms to the number of children and marriage. Here, we assume that marriage does not make a difference, thus, the mapping only varies on the number of children in the family. Presently, the following is implemented:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    " \\text{num of children} & & \\text{num of bedrooms} \\\\\n",
    " 0 &  \\to & 1 \\\\\n",
    " 1 & \\vdots & 2 \\\\\n",
    " 2 &  & 2 \\\\\n",
    " 3+ & \\to & 3 \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Map FMR data to EITC data (Variable)\n",
    "#assigned bedrooms to child counts\n",
    "repl_dict ={'Married, 0 Kid':'fmr1', 'Married, 1 Kid':'fmr2', 'Married, 2 Kids':'fmr2',\n",
    "       'Married, 3 Kids':'fmr3', 'Single, 0 Kid':'fmr1', 'Single, 1 Kid':'fmr2',\n",
    "       'Single, 2 Kids':'fmr2', 'Single, 3 Kids':'fmr3'}\n",
    "\n",
    "eitc['r_type'] = eitc.level_0.replace(repl_dict)\n",
    "\n",
    "haus_share = eitc[['level_0', 'haus_share', 'r_type', 'Nominal Earnings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reformat monthly fmr to annual cost of rent\n",
    "fmr_discount = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate amount of EITC housing aid each family type in each metro receives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "##II. Group by family type and loop over incomes\n",
    "################################################\n",
    "groups = haus_share.groupby(by = 'level_0')\n",
    "\n",
    "#place eachincome is placed into a dictionary entry\n",
    "aid_incomes = {}\n",
    "for income in income_vect:\n",
    "    aid_per_income = groups.apply(calc_haus_eitc, income=income, fmr=fmr_o*fmr_discount)\n",
    "    aid_incomes[income] = aid_per_income.unstack(level=0)\n",
    "    \n",
    "#concatenate dictionary into a 2-indexed data frame (flattened 3D)    \n",
    "one_family_aid = pd.concat(aid_incomes)\n",
    "one_family_aid.columns = one_family_aid.columns.levels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate families of each type in each income bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prop accounted for in income distribution counts\n",
      " 0.00    0.876222\n",
      "0.25    0.972034\n",
      "0.50    0.984475\n",
      "0.75    0.990173\n",
      "1.00    0.998135\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "############### 0. pre-checks and params ########################\n",
    "#it doesn't seem that the total eligible for eitc matches the distributional count of incomes\n",
    "print(\"Prop accounted for in income distribution counts\\n\",(tx_o[eagi_cols].sum(axis=1)/tx_o.eitc13).quantile(np.linspace(0,1,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tx = tx_o.copy()\n",
    "#################################################################\n",
    "################ I. compute proportions #########################\n",
    "#set proportion of ppl married - some Christian Science article (not sure if credible source)\n",
    "prop_married = 1-50.2/100  \n",
    "\n",
    "eqc_cols = tx.columns[tx.columns.str.contains(\"EQC\\d_\")]\n",
    "\n",
    "chld_prop = tx[eqc_cols].div(tx.eitc13,axis=0)\n",
    "m_chld_prop = chld_prop*prop_married\n",
    "s_chld_prop = chld_prop - m_chld_prop\n",
    "\n",
    "m_chld_prop.columns = m_chld_prop.columns + \"_married\"\n",
    "s_chld_prop.columns = s_chld_prop.columns + \"_single\"\n",
    "\n",
    "tx = pd.concat([tx, m_chld_prop,s_chld_prop],axis=1)\n",
    "eqc_cols = tx.columns[tx.columns.str.contains('EQC\\d_13_married|EQC\\d_13_single', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "############### II. multiply to across ##########################\n",
    "#here I make a 3D matrix with metros, bins, types on each axis \n",
    "#then flatten it into a 2D data frame. \n",
    "\n",
    "#Implicit broadcasting across two 2D matrices into a 3D matrix\n",
    "C_3D=np.einsum('ij,ik->jik',tx[eagi_cols],tx[eqc_cols])\n",
    "\n",
    "#flatten into a pandas dataframe\n",
    "C_2D=pd.Panel(np.rollaxis(C_3D,2)).to_frame()\n",
    "\n",
    "C_2D.columns = one_family_aid.columns\n",
    "\n",
    "C_2D.index = one_family_aid.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_figs = C_2D.sum(axis=1).groupby(level=1).sum().round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate total cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "############### aggregate aid and filers #########################\n",
    "disaggregated =np.multiply(C_2D, one_family_aid)\n",
    "\n",
    "#summing once gives us metro-level totals -> summing that gives us total\n",
    "total = disaggregated.sum(axis=1).sum()\n",
    "output_container['base_sim'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total EITC Housing Aid cost: 121.05 billion\n"
     ]
    }
   ],
   "source": [
    "print(\"Total EITC Housing Aid cost: %.2f billion\" %(output_container['base_sim']/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Supplemental Questions\n",
    "- varying parameters on original sim\n",
    "- number metros where families earning 52,400 recieve EITC housing aid\n",
    "- what if no one receives more aid than the median income earning family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vary_params(prcnt_of_income = .3,fmr_discount = 1,prop_married=prop_married, repl_dict = repl_dict, fmr=fmr_o[fmr_cols], tx = tx_o):\n",
    "\n",
    "    ######################################\n",
    "    ##I. Make a vector of income bin means\n",
    "    ######################################\n",
    "    min_earn = 2500\n",
    "    mid_earn = 37500\n",
    "    step = 5000\n",
    "    income_vect = np.linspace(min_earn,mid_earn,((mid_earn-min_earn)/step+1))\n",
    "\n",
    "    add_vect = [45000,52400]\n",
    "    income_vect = np.concatenate([income_vect, add_vect])\n",
    "\n",
    "    #calculate fair share of income for housing\n",
    "    eitc = eitc_o[['Nominal Earnings','level_0', 2014]].copy()\n",
    "    eitc['total_income'] = eitc['Nominal Earnings']+eitc[2014]\n",
    "    eitc['haus_share'] = eitc.total_income*prcnt_of_income\n",
    "\n",
    "    #remove \"Nominal\" from family description.\n",
    "    eitc.level_0.replace(\", Nominal\", \"\", regex=True, inplace=True)\n",
    "\n",
    "    eitc['r_type'] = eitc.level_0.replace(repl_dict)\n",
    "\n",
    "    haus_share = eitc[['level_0', 'haus_share', 'r_type', 'Nominal Earnings']]\n",
    "\n",
    "    #reformat monthly fmr to annual cost of rent\n",
    "    #fmr = fmr*fmr_discount\n",
    "\n",
    "    ################################################\n",
    "    ##II. Group by family type and loop over incomes\n",
    "    ################################################\n",
    "    groups = haus_share.groupby(by = 'level_0')\n",
    "\n",
    "    #place eachincome is placed into a dictionary entry\n",
    "    aid_incomes = {}\n",
    "    for income in income_vect:\n",
    "        aid_per_income = groups.apply(calc_haus_eitc, income=income, fmr = fmr*fmr_discount)\n",
    "        aid_incomes[income] = aid_per_income.unstack(level=0)\n",
    "\n",
    "    #concatenate dictionary into a 2-indexed data frame (flattened 3D)    \n",
    "    one_family_aid = pd.concat(aid_incomes)\n",
    "    one_family_aid.columns = one_family_aid.columns.levels[1]\n",
    "\n",
    "    #################################################################\n",
    "    ################ I. compute proportions #########################\n",
    "    eqc_cols = tx.columns[tx.columns.str.contains(\"EQC\\d_\")]\n",
    "\n",
    "    chld_prop = tx[eqc_cols].div(tx.eitc13,axis=0)\n",
    "    m_chld_prop = chld_prop*prop_married\n",
    "    s_chld_prop = chld_prop - m_chld_prop\n",
    "\n",
    "    m_chld_prop.columns = m_chld_prop.columns + \"_married\"\n",
    "    s_chld_prop.columns = s_chld_prop.columns + \"_single\"\n",
    "\n",
    "    tx = pd.concat([tx, m_chld_prop,s_chld_prop],axis=1)\n",
    "    eqc_cols = tx.columns[tx.columns.str.contains('EQC\\d_13_married|EQC\\d_13_single', regex=True)]\n",
    "\n",
    "    #################################################################\n",
    "    ############### II. multiply to across ##########################\n",
    "    #here I make a 3D matrix with metros, bins, types on each axis \n",
    "    #then flatten it into a 2D data frame. \n",
    "\n",
    "    #Implicit broadcasting across two 2D matrices into a 3D matrix\n",
    "    C_3D=np.einsum('ij,ik->jik',tx[eagi_cols],tx[eqc_cols])\n",
    "\n",
    "    #flatten into a pandas dataframe\n",
    "    C_2D=pd.Panel(np.rollaxis(C_3D,2)).to_frame()\n",
    "\n",
    "    C_2D.columns = one_family_aid.columns\n",
    "\n",
    "    C_2D.index = one_family_aid.index\n",
    "\n",
    "    ##################################################################\n",
    "    ############### aggregate aid and filers #########################\n",
    "    disaggregated =np.multiply(C_2D, one_family_aid)\n",
    "\n",
    "    #summing once gives us metro-level totals -> summing that gives us total\n",
    "    total = disaggregated.sum(axis=1).sum()\n",
    "    return(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check NY area which is '35620'\n",
    "disaggregated.groupby(level=1).sum().loc['35620'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.05\n"
     ]
    }
   ],
   "source": [
    "#test out sim function:\n",
    "print(\"%.2f\" %(vary_params()/1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test various cases:\n",
    "- marriage proportion is 40%\n",
    "- support only 80% and 90% of FMR\n",
    "- allow a higher income proportion to go to housing: 40 and 45\n",
    "- put singles with no children into studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_container['low_marr_prop'] = vary_params(prop_married = .4)\n",
    "output_container['sub_fmr_rent_80'] = vary_params(fmr_discount=.8)\n",
    "output_container['sub_fmr_rent_90'] = vary_params(fmr_discount=.9)\n",
    "\n",
    "output_container['haus_share_40'] = vary_params(prcnt_of_income = .4)\n",
    "output_container['haus_share_50'] = vary_params(prcnt_of_income = .5)\n",
    "\n",
    "repl_dict_studio ={'Married, 0 Kid':'fmr0', 'Married, 1 Kid':'fmr2', 'Married, 2 Kids':'fmr2',\n",
    "       'Married, 3 Kids':'fmr3', 'Single, 0 Kid':'fmr0', 'Single, 1 Kid':'fmr2',\n",
    "       'Single, 2 Kids':'fmr2', 'Single, 3 Kids':'fmr3'}\n",
    "output_container['tight_living'] = vary_params(repl_dict = repl_dict_studio)\n",
    "\n",
    "output_container['sub_fmr_rent_90_haus_share_40'] = vary_params(prcnt_of_income = .4, fmr_discount = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_sim': 121048065013.81049,\n",
       " 'haus_share_40': 93715802445.02422,\n",
       " 'haus_share_50': 73102699122.02,\n",
       " 'low_marr_prop': 120861615671.89114,\n",
       " 'sub_fmr_rent_80': 79891037223.741,\n",
       " 'sub_fmr_rent_90': 99999745586.42644,\n",
       " 'sub_fmr_rent_90_haus_share_40': 75420693594.25081,\n",
       " 'tight_living': 117088153961.4179}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capping EITC benefits at the city median income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantiles = np.divide(C_3D,np.cumsum(C_3D, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the median income values\n",
    "\"\"\"\n",
    "Cool stuff: in essence, we have the following algorithm\n",
    "-consider only values greater than .5 in the cumulative percentiles of each income bin\n",
    "-find the minimum on the masked array -> these are the medians\n",
    "-use the rows set as true as the identifiers of the median income in the index\n",
    "\"\"\"\n",
    "masked_quantiles = ma.masked_where(quantiles<=.5,quantiles)\n",
    "median_idx = masked_quantiles.argmin(0)\n",
    "median_idx = np.where(masked_quantiles == masked_quantiles.min(axis=0))\n",
    "median_mat = np.zeros(quantiles.shape, dtype=bool)\n",
    "median_mat[median_idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 357, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#flatten into a pandas dataframe\n",
    "median_2D=pd.Panel(np.rollaxis(median_mat,2)).to_frame()\n",
    "\n",
    "median_2D.columns = one_family_aid.columns\n",
    "\n",
    "median_2D.index = one_family_aid.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAGI0_13</th>\n",
       "      <th>EAGI5_13</th>\n",
       "      <th>EAGI10_13</th>\n",
       "      <th>EAGI15_13</th>\n",
       "      <th>EAGI20_13</th>\n",
       "      <th>EAGI25_13</th>\n",
       "      <th>EAGI30_13</th>\n",
       "      <th>EAGI35_13</th>\n",
       "      <th>EAGI40_13</th>\n",
       "      <th>EAGI50_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10180</th>\n",
       "      <td>0.093470</td>\n",
       "      <td>0.257948</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.589849</td>\n",
       "      <td>0.704124</td>\n",
       "      <td>0.802934</td>\n",
       "      <td>0.884988</td>\n",
       "      <td>0.945133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10420</th>\n",
       "      <td>0.115991</td>\n",
       "      <td>0.304029</td>\n",
       "      <td>0.528612</td>\n",
       "      <td>0.651629</td>\n",
       "      <td>0.745072</td>\n",
       "      <td>0.831303</td>\n",
       "      <td>0.905655</td>\n",
       "      <td>0.958074</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10500</th>\n",
       "      <td>0.057985</td>\n",
       "      <td>0.235216</td>\n",
       "      <td>0.504913</td>\n",
       "      <td>0.675505</td>\n",
       "      <td>0.797185</td>\n",
       "      <td>0.884118</td>\n",
       "      <td>0.940377</td>\n",
       "      <td>0.978090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EAGI0_13  EAGI5_13  EAGI10_13  EAGI15_13  EAGI20_13  EAGI25_13  \\\n",
       "10180  0.093470  0.257948   0.456057   0.589849   0.704124   0.802934   \n",
       "10420  0.115991  0.304029   0.528612   0.651629   0.745072   0.831303   \n",
       "10500  0.057985  0.235216   0.504913   0.675505   0.797185   0.884118   \n",
       "\n",
       "       EAGI30_13  EAGI35_13  EAGI40_13  EAGI50_13  \n",
       "10180   0.884988   0.945133   1.000000        1.0  \n",
       "10420   0.905655   0.958074   0.999991        1.0  \n",
       "10500   0.940377   0.978090   1.000000        1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just double check the results from above\n",
    "np.divide(tx[eagi_cols].cumsum(axis=1),tx[eagi_cols].sum(axis=1).reshape(357,1)).head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the amount of aid the median income family in each metro is getting\n",
    "median_metro_aid = one_family_aid[median_2D].reset_index(level=0, drop=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the amount of aid the median income family in each metro is getting\n",
    "median_metro_aid = one_family_aid[median_2D].reset_index(level=0, drop=True).dropna()\n",
    "comparison = pd.concat([median_metro_aid]*10)\n",
    "\n",
    "#inefficient way of making the comparison matrix the same size as the original matrix\n",
    "comparison.index = one_family_aid.index\n",
    "\n",
    "#also inefficient but copy in order to not lose the original matrix\n",
    "X = one_family_aid.copy()\n",
    "\n",
    "#set the values that are above the median to np.nan\n",
    "X[comparison <= one_family_aid] = np.nan\n",
    "\n",
    "#fill nan values with the median values\n",
    "X.fillna(comparison, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "############### aggregate aid and filers #########################\n",
    "disaggregated_med =np.multiply(C_2D, X)\n",
    "\n",
    "#summing once gives us metro-level totals -> summing that gives us total\n",
    "output_container['median_capped'] = disaggregated_med.sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total EITC Housing Aid cost: 100.94 billion\n"
     ]
    }
   ],
   "source": [
    "print(\"Total EITC Housing Aid cost: %.2f billion\" %(output_container['median_capped']/1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcome_series = (pd.Series(output_container)/1e9).round(2).to_frame()\n",
    "outcome_series.columns = [\"total cost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>haus_share_50</th>\n",
       "      <td>73.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_fmr_rent_90_haus_share_40</th>\n",
       "      <td>75.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_fmr_rent_80</th>\n",
       "      <td>79.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haus_share_40</th>\n",
       "      <td>93.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_fmr_rent_90</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_capped</th>\n",
       "      <td>100.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tight_living</th>\n",
       "      <td>117.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_marr_prop</th>\n",
       "      <td>120.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_sim</th>\n",
       "      <td>121.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               total cost\n",
       "haus_share_50                       73.10\n",
       "sub_fmr_rent_90_haus_share_40       75.42\n",
       "sub_fmr_rent_80                     79.89\n",
       "haus_share_40                       93.72\n",
       "sub_fmr_rent_90                    100.00\n",
       "median_capped                      100.94\n",
       "tight_living                       117.09\n",
       "low_marr_prop                      120.86\n",
       "base_sim                           121.05"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_series.sort_values(by='total cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Number of metros where families earn 52,400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of metros where family earning 52400 gets EITC housing aid: 55\n"
     ]
    }
   ],
   "source": [
    "#Cacl number of metros where family earning ... \n",
    "max_inc_aid = (one_family_aid.loc[52400]>0).sum(axis=1).sum()\n",
    "print(\"Number of metros where family earning 52400 gets EITC housing aid: %d\" %max_inc_aid)\n",
    "\n",
    "expens_cbsas = one_family_aid.loc[52400,'Married, 3 Kids'].loc[(one_family_aid.loc[52400, \"Married, 3 Kids\"]>0)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11260                       Anchorage, AK\n",
       "12100         Atlantic City-Hammonton, NJ\n",
       "12420    Austin-Round Rock-San Marcos, TX\n",
       "12580                Baltimore-Towson, MD\n",
       "12700                 Barnstable Town, MA\n",
       "Name: Areaname, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmr_o.loc[expens_cbsas].Areaname[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some additional output tables\n",
    "- 20 top and bottom cities that contribute most in terms of cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##make the top 20 and bottom 20 table of expenditures\n",
    "cost_per_metro = disaggregated.sum(axis=1).unstack(level=0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost_per_metro = pd.concat([cost_per_metro, pop_figs], axis=1)\n",
    "cost_per_metro.columns = ['cost', 'recipients']\n",
    "cost_per_metro['cost_per_recipient'] = (cost_per_metro.cost/cost_per_metro.recipients).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost_per_metro.head()\n",
    "cost_per_metro.sort_values(\"cost\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottom_20_cbsa = cost_per_metro.iloc[:20].index\n",
    "bottom_20_costs = pd.concat([fmr_o.loc[bottom_20_cbsa].Areaname, cost_per_metro.iloc[:20][['cost','cost_per_recipient']]],axis=1)\n",
    "bottom_20_costs.columns = ['Metro','Cost', 'CPR']\n",
    "bottom_20_costs.Cost =(bottom_20_costs.Cost/1e6).round(2)\n",
    "bottom_20_costs.rename(columns = {'Cost':\"Cost in millions\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metro</th>\n",
       "      <th>Cost in millions</th>\n",
       "      <th>CPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11180</th>\n",
       "      <td>Ames, IA</td>\n",
       "      <td>10.49</td>\n",
       "      <td>3268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30300</th>\n",
       "      <td>Lewiston, ID-WA</td>\n",
       "      <td>11.26</td>\n",
       "      <td>2429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22540</th>\n",
       "      <td>Fond du Lac, WI</td>\n",
       "      <td>13.51</td>\n",
       "      <td>2469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24500</th>\n",
       "      <td>Great Falls, MT</td>\n",
       "      <td>15.74</td>\n",
       "      <td>2344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24220</th>\n",
       "      <td>Grand Forks, ND-MN</td>\n",
       "      <td>16.16</td>\n",
       "      <td>2989.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Metro  Cost in millions     CPR\n",
       "11180            Ames, IA             10.49  3268.0\n",
       "30300     Lewiston, ID-WA             11.26  2429.0\n",
       "22540     Fond du Lac, WI             13.51  2469.0\n",
       "24500     Great Falls, MT             15.74  2344.0\n",
       "24220  Grand Forks, ND-MN             16.16  2989.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_20_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metro</th>\n",
       "      <th>Cost in billions</th>\n",
       "      <th>CPR</th>\n",
       "      <th>Metro</th>\n",
       "      <th>Cost in millions</th>\n",
       "      <th>CPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las Vegas-Paradise, NV</td>\n",
       "      <td>1.09</td>\n",
       "      <td>5976.0</td>\n",
       "      <td>Ames, IA</td>\n",
       "      <td>10.49</td>\n",
       "      <td>3268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seattle-Bellevue, WA</td>\n",
       "      <td>1.27</td>\n",
       "      <td>6523.0</td>\n",
       "      <td>Lewiston, ID-WA</td>\n",
       "      <td>11.26</td>\n",
       "      <td>2429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "      <td>1.40</td>\n",
       "      <td>5204.0</td>\n",
       "      <td>Fond du Lac, WI</td>\n",
       "      <td>13.51</td>\n",
       "      <td>2469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Orlando-Kissimmee-Sanford, FL</td>\n",
       "      <td>1.44</td>\n",
       "      <td>5506.0</td>\n",
       "      <td>Great Falls, MT</td>\n",
       "      <td>15.74</td>\n",
       "      <td>2344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detroit-Warren-Livonia, MI</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4431.0</td>\n",
       "      <td>Grand Forks, ND-MN</td>\n",
       "      <td>16.16</td>\n",
       "      <td>2989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baltimore-Towson, MD</td>\n",
       "      <td>1.66</td>\n",
       "      <td>8541.0</td>\n",
       "      <td>Logan, UT-ID</td>\n",
       "      <td>16.83</td>\n",
       "      <td>1977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phoenix-Mesa-Glendale, AZ</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5297.0</td>\n",
       "      <td>Pocatello, ID</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boston-Cambridge-Quincy, MA-NH</td>\n",
       "      <td>2.16</td>\n",
       "      <td>8632.0</td>\n",
       "      <td>Bismarck, ND</td>\n",
       "      <td>17.84</td>\n",
       "      <td>2917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>San Diego-Carlsbad-San Marcos, CA</td>\n",
       "      <td>2.21</td>\n",
       "      <td>9284.0</td>\n",
       "      <td>Carson City, NV</td>\n",
       "      <td>18.01</td>\n",
       "      <td>4172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Atlanta-Sandy Springs-Marietta, GA</td>\n",
       "      <td>2.41</td>\n",
       "      <td>4357.0</td>\n",
       "      <td>Manhattan, KS</td>\n",
       "      <td>18.18</td>\n",
       "      <td>3199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Austin County, TX</td>\n",
       "      <td>2.53</td>\n",
       "      <td>4466.0</td>\n",
       "      <td>Cumberland, MD-WV</td>\n",
       "      <td>18.28</td>\n",
       "      <td>2435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>2.67</td>\n",
       "      <td>4454.0</td>\n",
       "      <td>Dubuque, IA</td>\n",
       "      <td>18.30</td>\n",
       "      <td>3091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Riverside-San Bernardino-Ontario, CA</td>\n",
       "      <td>2.94</td>\n",
       "      <td>7032.0</td>\n",
       "      <td>Mankato-North Mankato, MN</td>\n",
       "      <td>18.46</td>\n",
       "      <td>3221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Philadelphia-Camden-Wilmington, PA-NJ-DE-MD</td>\n",
       "      <td>3.03</td>\n",
       "      <td>6979.0</td>\n",
       "      <td>Corvallis, OR</td>\n",
       "      <td>18.86</td>\n",
       "      <td>4378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oakland-Fremont, CA</td>\n",
       "      <td>3.13</td>\n",
       "      <td>13749.0</td>\n",
       "      <td>Parkersburg-Marietta-Vienna, WV-OH</td>\n",
       "      <td>18.99</td>\n",
       "      <td>2257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD</td>\n",
       "      <td>3.44</td>\n",
       "      <td>9881.0</td>\n",
       "      <td>Casper, WY</td>\n",
       "      <td>19.38</td>\n",
       "      <td>3476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chicago-Joliet-Naperville, IL</td>\n",
       "      <td>3.51</td>\n",
       "      <td>4756.0</td>\n",
       "      <td>Gadsden, AL</td>\n",
       "      <td>19.81</td>\n",
       "      <td>1757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fort Lauderdale, FL</td>\n",
       "      <td>5.90</td>\n",
       "      <td>7965.0</td>\n",
       "      <td>Cape Girardeau-Jackson, MO-IL</td>\n",
       "      <td>19.91</td>\n",
       "      <td>2674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Los Angeles-Long Beach, CA</td>\n",
       "      <td>12.48</td>\n",
       "      <td>11120.0</td>\n",
       "      <td>Kokomo, IN</td>\n",
       "      <td>20.26</td>\n",
       "      <td>2611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bergen-Passaic, NJ</td>\n",
       "      <td>16.75</td>\n",
       "      <td>9955.0</td>\n",
       "      <td>Wausau, WI</td>\n",
       "      <td>20.46</td>\n",
       "      <td>2282.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Metro  Cost in billions      CPR  \\\n",
       "0                        Las Vegas-Paradise, NV              1.09   5976.0   \n",
       "1                          Seattle-Bellevue, WA              1.27   6523.0   \n",
       "2           Tampa-St. Petersburg-Clearwater, FL              1.40   5204.0   \n",
       "3                 Orlando-Kissimmee-Sanford, FL              1.44   5506.0   \n",
       "4                    Detroit-Warren-Livonia, MI              1.62   4431.0   \n",
       "5                          Baltimore-Towson, MD              1.66   8541.0   \n",
       "6                     Phoenix-Mesa-Glendale, AZ              1.81   5297.0   \n",
       "7                Boston-Cambridge-Quincy, MA-NH              2.16   8632.0   \n",
       "8             San Diego-Carlsbad-San Marcos, CA              2.21   9284.0   \n",
       "9            Atlanta-Sandy Springs-Marietta, GA              2.41   4357.0   \n",
       "10                            Austin County, TX              2.53   4466.0   \n",
       "11                                   Dallas, TX              2.67   4454.0   \n",
       "12         Riverside-San Bernardino-Ontario, CA              2.94   7032.0   \n",
       "13  Philadelphia-Camden-Wilmington, PA-NJ-DE-MD              3.03   6979.0   \n",
       "14                          Oakland-Fremont, CA              3.13  13749.0   \n",
       "15    Washington-Arlington-Alexandria, DC-VA-MD              3.44   9881.0   \n",
       "16                Chicago-Joliet-Naperville, IL              3.51   4756.0   \n",
       "17                          Fort Lauderdale, FL              5.90   7965.0   \n",
       "18                   Los Angeles-Long Beach, CA             12.48  11120.0   \n",
       "19                           Bergen-Passaic, NJ             16.75   9955.0   \n",
       "\n",
       "                                 Metro  Cost in millions     CPR  \n",
       "0                             Ames, IA             10.49  3268.0  \n",
       "1                      Lewiston, ID-WA             11.26  2429.0  \n",
       "2                      Fond du Lac, WI             13.51  2469.0  \n",
       "3                      Great Falls, MT             15.74  2344.0  \n",
       "4                   Grand Forks, ND-MN             16.16  2989.0  \n",
       "5                         Logan, UT-ID             16.83  1977.0  \n",
       "6                        Pocatello, ID             17.00  2430.0  \n",
       "7                         Bismarck, ND             17.84  2917.0  \n",
       "8                      Carson City, NV             18.01  4172.0  \n",
       "9                        Manhattan, KS             18.18  3199.0  \n",
       "10                   Cumberland, MD-WV             18.28  2435.0  \n",
       "11                         Dubuque, IA             18.30  3091.0  \n",
       "12           Mankato-North Mankato, MN             18.46  3221.0  \n",
       "13                       Corvallis, OR             18.86  4378.0  \n",
       "14  Parkersburg-Marietta-Vienna, WV-OH             18.99  2257.0  \n",
       "15                          Casper, WY             19.38  3476.0  \n",
       "16                         Gadsden, AL             19.81  1757.0  \n",
       "17       Cape Girardeau-Jackson, MO-IL             19.91  2674.0  \n",
       "18                          Kokomo, IN             20.26  2611.0  \n",
       "19                          Wausau, WI             20.46  2282.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_cbsa = cost_per_metro.iloc[-20:].index\n",
    "top_20_costs = pd.concat([fmr_o.loc[top_20_cbsa].Areaname, cost_per_metro.iloc[-20:][['cost','cost_per_recipient']]],axis=1)\n",
    "top_20_costs.columns = ['Metro','Cost', 'CPR']\n",
    "top_20_costs.Cost = (top_20_costs.Cost/1e9).round(2)\n",
    "top_20_costs.rename(columns = {'Cost':\"Cost in billions\"},inplace=True)\n",
    "pd.concat([top_20_costs.reset_index(drop=True),bottom_20_costs.reset_index(drop=True)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A metric of EITC housing recipients. Using indexers defined at the top:\n",
    "$$\n",
    "\\sum_{t\\in T} = \\frac { \\sum_y I(h_{l,t,y}=0) }{ \\sum_y I(h_{l,t,y} \\geq 0 ) }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yes_numbers = np.multiply(C_2D, one_family_aid>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average proportion of non-qualifiers: 0.43\n"
     ]
    }
   ],
   "source": [
    "non_receivers = 1-(np.divide(yes_numbers,C_2D).fillna(0).sum(axis=1)/8).unstack(level=0).sum(axis=1)/10\n",
    "non_receivers.sort_values(inplace=True)\n",
    "print(\"Average proportion of non-qualifiers: %.02f\" %non_receivers.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_low_prop=pd.concat([fmr_o.loc[non_receivers.iloc[-20:].index].Areaname, non_receivers.iloc[-20:]], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_low_prop.columns = ['metro','prop of non-recipients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metro</th>\n",
       "      <th>prop of non-recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mansfield, OH</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hickory-Lenoir-Morganton, NC</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cumberland, MD-WV</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Youngstown-Warren-Boardman, OH</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Darlington County, SC</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morristown, TN</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pine Bluff, AR</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jonesboro, AR</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Joplin, MO</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Parkersburg-Marietta-Vienna, WV-OH</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steubenville-Weirton, OH-WV</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Decatur, AL</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Elizabethtown, KY</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Benton County, IA</td>\n",
       "      <td>0.5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kingsport-Bristol-Bristol, TN-VA</td>\n",
       "      <td>0.5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Owensboro, KY</td>\n",
       "      <td>0.5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wheeling, WV-OH</td>\n",
       "      <td>0.5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gadsden, AL</td>\n",
       "      <td>0.5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fort Smith, AR-OK</td>\n",
       "      <td>0.5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dothan, AL</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 metro  prop of non-recipients\n",
       "0                        Mansfield, OH                  0.5500\n",
       "1         Hickory-Lenoir-Morganton, NC                  0.5500\n",
       "2                    Cumberland, MD-WV                  0.5500\n",
       "3       Youngstown-Warren-Boardman, OH                  0.5500\n",
       "4                Darlington County, SC                  0.5500\n",
       "5                       Morristown, TN                  0.5500\n",
       "6                       Pine Bluff, AR                  0.5500\n",
       "7                        Jonesboro, AR                  0.5625\n",
       "8                           Joplin, MO                  0.5625\n",
       "9   Parkersburg-Marietta-Vienna, WV-OH                  0.5625\n",
       "10         Steubenville-Weirton, OH-WV                  0.5625\n",
       "11                         Decatur, AL                  0.5625\n",
       "12                   Elizabethtown, KY                  0.5625\n",
       "13                   Benton County, IA                  0.5750\n",
       "14    Kingsport-Bristol-Bristol, TN-VA                  0.5750\n",
       "15                       Owensboro, KY                  0.5750\n",
       "16                     Wheeling, WV-OH                  0.5875\n",
       "17                         Gadsden, AL                  0.5875\n",
       "18                   Fort Smith, AR-OK                  0.5875\n",
       "19                          Dothan, AL                  0.6250"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_low_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
